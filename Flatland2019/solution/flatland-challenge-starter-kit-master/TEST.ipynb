{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "\nWe cannot seem to find the env file paths at the required location.\nDid you remember to set the AICROWD_TESTS_FOLDER environment variable to point to the location of the Tests folder ? \nWe are currently looking at `/tmp/flatland_envs` for the tests",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b37fe2f38f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     observation, info = remote_client.env_create(\n\u001b[0;32m---> 64\u001b[0;31m                     \u001b[0mobs_builder_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_observation_builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 )\n\u001b[1;32m     66\u001b[0m     \u001b[0menv_creation_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flatland-rl/lib/python3.6/site-packages/flatland/evaluators/client.py\u001b[0m in \u001b[0;36menv_create\u001b[0;34m(self, obs_builder_object)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;34m\"Did you remember to set the AICROWD_TESTS_FOLDER environment variable \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;34m\"to point to the location of the Tests folder ? \\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0;34m\"We are currently looking at `{}` for the tests\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_envs_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             )\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: \nWe cannot seem to find the env file paths at the required location.\nDid you remember to set the AICROWD_TESTS_FOLDER environment variable to point to the location of the Tests folder ? \nWe are currently looking at `/tmp/flatland_envs` for the tests"
     ]
    }
   ],
   "source": [
    "from flatland.evaluators.client import FlatlandRemoteClient\n",
    "from flatland.core.env_observation_builder import DummyObservationBuilder\n",
    "from my_observation_builder import CustomObservationBuilder\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "# Instantiate a Remote Client\n",
    "#####################################################################\n",
    "remote_client = FlatlandRemoteClient()\n",
    "\n",
    "#####################################################################\n",
    "# Define your custom controller\n",
    "#\n",
    "# which can take an observation, and the number of agents and \n",
    "# compute the necessary action for this step for all (or even some)\n",
    "# of the agents\n",
    "#####################################################################\n",
    "def my_controller(obs, number_of_agents):\n",
    "    _action = {}\n",
    "    for _idx in range(number_of_agents):\n",
    "        _action[_idx] = np.random.randint(0, 5)\n",
    "    return _action\n",
    "\n",
    "#####################################################################\n",
    "# Instantiate your custom Observation Builder\n",
    "# \n",
    "# You can build your own Observation Builder by following \n",
    "# the example here : \n",
    "# https://gitlab.aicrowd.com/flatland/flatland/blob/master/flatland/envs/observations.py#L14\n",
    "#####################################################################\n",
    "my_observation_builder = CustomObservationBuilder()\n",
    "\n",
    "# Or if you want to use your own approach to build the observation from the env_step, \n",
    "# please feel free to pass a DummyObservationBuilder() object as mentioned below,\n",
    "# and that will just return a placeholder True for all observation, and you \n",
    "# can build your own Observation for all the agents as your please.\n",
    "# my_observation_builder = DummyObservationBuilder()\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "# Main evaluation loop\n",
    "#\n",
    "# This iterates over an arbitrary number of env evaluations\n",
    "#####################################################################\n",
    "evaluation_number = 0\n",
    "while True:\n",
    "\n",
    "    evaluation_number += 1\n",
    "    # Switch to a new evaluation environemnt\n",
    "    # \n",
    "    # a remote_client.env_create is similar to instantiating a \n",
    "    # RailEnv and then doing a env.reset()\n",
    "    # hence it returns the first observation from the \n",
    "    # env.reset()\n",
    "    # \n",
    "    # You can also pass your custom observation_builder object\n",
    "    # to allow you to have as much control as you wish \n",
    "    # over the observation of your choice.\n",
    "    time_start = time.time()\n",
    "    observation, info = remote_client.env_create(\n",
    "                    obs_builder_object=my_observation_builder\n",
    "                )\n",
    "    env_creation_time = time.time() - time_start\n",
    "    if not observation:\n",
    "        #\n",
    "        # If the remote_client returns False on a `env_create` call,\n",
    "        # then it basically means that your agent has already been \n",
    "        # evaluated on all the required evaluation environments,\n",
    "        # and hence its safe to break out of the main evaluation loop\n",
    "        break\n",
    "    \n",
    "    print(\"Evaluation Number : {}\".format(evaluation_number))\n",
    "\n",
    "    #####################################################################\n",
    "    # Access to a local copy of the environment\n",
    "    # \n",
    "    #####################################################################\n",
    "    # Note: You can access a local copy of the environment \n",
    "    # by using : \n",
    "    #       remote_client.env \n",
    "    # \n",
    "    # But please ensure to not make any changes (or perform any action) on \n",
    "    # the local copy of the env, as then it will diverge from \n",
    "    # the state of the remote copy of the env, and the observations and \n",
    "    # rewards, etc will behave unexpectedly\n",
    "    # \n",
    "    # You can however probe the local_env instance to get any information\n",
    "    # you need from the environment. It is a valid RailEnv instance.\n",
    "    local_env = remote_client.env\n",
    "    number_of_agents = len(local_env.agents)\n",
    "\n",
    "    # Now we enter into another infinite loop where we \n",
    "    # compute the actions for all the individual steps in this episode\n",
    "    # until the episode is `done`\n",
    "    # \n",
    "    # An episode is considered done when either all the agents have \n",
    "    # reached their target destination\n",
    "    # or when the number of time steps has exceed max_time_steps, which \n",
    "    # is defined by : \n",
    "    #\n",
    "    # max_time_steps = int(4 * 2 * (env.width + env.height + 20))\n",
    "    #\n",
    "    time_taken_by_controller = []\n",
    "    time_taken_per_step = []\n",
    "    steps = 0\n",
    "    \n",
    "    env_renderer = RenderTool(env)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        \n",
    "        \n",
    "        #####################################################################\n",
    "        # Evaluation of a single episode\n",
    "        #\n",
    "        #####################################################################\n",
    "        # Compute the action for this step by using the previously \n",
    "        # defined controller\n",
    "        time_start = time.time()\n",
    "        action = my_controller(observation, number_of_agents)\n",
    "        time_taken = time.time() - time_start\n",
    "        time_taken_by_controller.append(time_taken)\n",
    "\n",
    "        # Perform the chosen action on the environment.\n",
    "        # The action gets applied to both the local and the remote copy \n",
    "        # of the environment instance, and the observation is what is \n",
    "        # returned by the local copy of the env, and the rewards, and done and info\n",
    "        # are returned by the remote copy of the env\n",
    "        time_start = time.time()\n",
    "        observation, all_rewards, done, info = remote_client.env_step(action)\n",
    "        steps += 1\n",
    "        time_taken = time.time() - time_start\n",
    "        time_taken_per_step.append(time_taken)\n",
    "        env_renderer.render_env(show=True, frames=False, show_observations=False)\n",
    "        time.sleep(0.3)\n",
    "        if done['__all__']:\n",
    "            print(\"Reward : \", sum(list(all_rewards.values())))\n",
    "            #\n",
    "            # When done['__all__'] == True, then the evaluation of this \n",
    "            # particular Env instantiation is complete, and we can break out \n",
    "            # of this loop, and move onto the next Env evaluation\n",
    "            break\n",
    "    \n",
    "    np_time_taken_by_controller = np.array(time_taken_by_controller)\n",
    "    np_time_taken_per_step = np.array(time_taken_per_step)\n",
    "    print(\"=\"*100)\n",
    "    print(\"=\"*100)\n",
    "    print(\"Evaluation Number : \", evaluation_number)\n",
    "    print(\"Current Env Path : \", remote_client.current_env_path)\n",
    "    print(\"Env Creation Time : \", env_creation_time)\n",
    "    print(\"Number of Steps : \", steps)\n",
    "    print(\"Mean/Std of Time taken by Controller : \", np_time_taken_by_controller.mean(), np_time_taken_by_controller.std())\n",
    "    print(\"Mean/Std of Time per Step : \", np_time_taken_per_step.mean(), np_time_taken_per_step.std())\n",
    "    print(\"=\"*100)\n",
    "\n",
    "print(\"Evaluation of all environments complete...\")\n",
    "########################################################################\n",
    "# Submit your Results\n",
    "# \n",
    "# Please do not forget to include this call, as this triggers the \n",
    "# final computation of the score statistics, video generation, etc\n",
    "# and is necesaary to have your submission marked as successfully evaluated\n",
    "########################################################################\n",
    "print(remote_client.submit())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
